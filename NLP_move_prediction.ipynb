{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first off all we imported libraries which we need\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rated</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_move_at</th>\n",
       "      <th>turns</th>\n",
       "      <th>victory_status</th>\n",
       "      <th>winner</th>\n",
       "      <th>increment_code</th>\n",
       "      <th>white_id</th>\n",
       "      <th>white_rating</th>\n",
       "      <th>black_id</th>\n",
       "      <th>black_rating</th>\n",
       "      <th>moves</th>\n",
       "      <th>opening_eco</th>\n",
       "      <th>opening_name</th>\n",
       "      <th>opening_ply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TZJHLljE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.504210e+12</td>\n",
       "      <td>1.504210e+12</td>\n",
       "      <td>13</td>\n",
       "      <td>outoftime</td>\n",
       "      <td>white</td>\n",
       "      <td>15+2</td>\n",
       "      <td>bourgris</td>\n",
       "      <td>1500</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1191</td>\n",
       "      <td>d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...</td>\n",
       "      <td>D10</td>\n",
       "      <td>Slav Defense: Exchange Variation</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l1NXvwaE</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>16</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>5+10</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1322</td>\n",
       "      <td>skinnerua</td>\n",
       "      <td>1261</td>\n",
       "      <td>d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...</td>\n",
       "      <td>B00</td>\n",
       "      <td>Nimzowitsch Defense: Kennedy Variation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mIICvQHh</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>61</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>5+10</td>\n",
       "      <td>ischia</td>\n",
       "      <td>1496</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1500</td>\n",
       "      <td>e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...</td>\n",
       "      <td>C20</td>\n",
       "      <td>King's Pawn Game: Leonardis Variation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kWKvrqYL</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504110e+12</td>\n",
       "      <td>1.504110e+12</td>\n",
       "      <td>61</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>20+0</td>\n",
       "      <td>daniamurashov</td>\n",
       "      <td>1439</td>\n",
       "      <td>adivanov2009</td>\n",
       "      <td>1454</td>\n",
       "      <td>d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...</td>\n",
       "      <td>D02</td>\n",
       "      <td>Queen's Pawn Game: Zukertort Variation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9tXo1AUZ</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504030e+12</td>\n",
       "      <td>1.504030e+12</td>\n",
       "      <td>95</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>30+3</td>\n",
       "      <td>nik221107</td>\n",
       "      <td>1523</td>\n",
       "      <td>adivanov2009</td>\n",
       "      <td>1469</td>\n",
       "      <td>e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...</td>\n",
       "      <td>C41</td>\n",
       "      <td>Philidor Defense</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  rated    created_at  last_move_at  turns victory_status winner  \\\n",
       "0  TZJHLljE  False  1.504210e+12  1.504210e+12     13      outoftime  white   \n",
       "1  l1NXvwaE   True  1.504130e+12  1.504130e+12     16         resign  black   \n",
       "2  mIICvQHh   True  1.504130e+12  1.504130e+12     61           mate  white   \n",
       "3  kWKvrqYL   True  1.504110e+12  1.504110e+12     61           mate  white   \n",
       "4  9tXo1AUZ   True  1.504030e+12  1.504030e+12     95           mate  white   \n",
       "\n",
       "  increment_code       white_id  white_rating      black_id  black_rating  \\\n",
       "0           15+2       bourgris          1500          a-00          1191   \n",
       "1           5+10           a-00          1322     skinnerua          1261   \n",
       "2           5+10         ischia          1496          a-00          1500   \n",
       "3           20+0  daniamurashov          1439  adivanov2009          1454   \n",
       "4           30+3      nik221107          1523  adivanov2009          1469   \n",
       "\n",
       "                                               moves opening_eco  \\\n",
       "0  d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...         D10   \n",
       "1  d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...         B00   \n",
       "2  e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...         C20   \n",
       "3  d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...         D02   \n",
       "4  e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...         C41   \n",
       "\n",
       "                             opening_name  opening_ply  \n",
       "0        Slav Defense: Exchange Variation            5  \n",
       "1  Nimzowitsch Defense: Kennedy Variation            4  \n",
       "2   King's Pawn Game: Leonardis Variation            3  \n",
       "3  Queen's Pawn Game: Zukertort Variation            3  \n",
       "4                        Philidor Defense            5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess_df = pd.read_csv(\"data/games.csv\")\n",
    "chess_df = chess_df[chess_df.turns > 5]\n",
    "chess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...\n",
       "1    d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...\n",
       "2    e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...\n",
       "3    d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...\n",
       "4    e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...\n",
       "Name: moves, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = chess_df.moves\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2694"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words = len(tokenizer.word_index) + 1 \n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 8],\n",
       " [5, 8, 11],\n",
       " [5, 8, 11, 23],\n",
       " [5, 8, 11, 23, 74],\n",
       " [5, 8, 11, 23, 74, 12]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences = []\n",
    "\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    \n",
    "    for i in range(1, len(token_list)):\n",
    "        if i < 10:\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "        else:\n",
    "            n_gram_sequence = token_list[i-9:i+1]\n",
    "        \n",
    "input_sequences[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 58, 295, 44, 12, 21, 4, 2, 60]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences[-1][-9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0, 0, 0, 0, 0, 0, 5, 8], dtype=int32),\n",
       " array([ 0,  0,  0,  0,  0,  0,  0,  5,  8, 11], dtype=int32),\n",
       " array([ 0,  0,  0,  0,  0,  0,  5,  8, 11, 23], dtype=int32),\n",
       " array([ 0,  0,  0,  0,  0,  5,  8, 11, 23, 74], dtype=int32),\n",
       " array([ 0,  0,  0,  0,  5,  8, 11, 23, 74, 12], dtype=int32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sentences = []\n",
    "\n",
    "batchsize = 20\n",
    "batches = int(len(input_sequences) / batchsize) + 1\n",
    "\n",
    "for batch in range(batches):\n",
    "        padded_sentences_batch = pad_sequences(input_sequences[batchsize*batch:batchsize*(batch+1)], maxlen=max_sequence_len)\n",
    "        \n",
    "        for sentence in padded_sentences_batch:\n",
    "            \n",
    "            padded_sentences.append(sentence)\n",
    "\n",
    "padded_sentences[0:5]\n",
    "\n",
    "tokenizer.texts_to_sequences([\"e4  e5 Bc4 nc6 Qh5 nf6 Qxf7\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 6, 18, 7, 111, 4, 348]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer.texts_to_sequences([\"e4  e5 Bc4 nc6 Qh5 nf6 Qxf7\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://medium.datadriveninvestor.com/keras-training-on-large-datasets-3e9d9dbc09d4\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class My_Generator(Sequence):\n",
    "\n",
    "    def __init__(self, data, labels, batch_size):\n",
    "        self.data, self.labels = data, labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.data) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        batch_x = self.data[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        return np.array(batch_x), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "labels = []\n",
    "\n",
    "for i in padded_sentences:\n",
    "    X.append(i[0:len(i) - 1])\n",
    "    labels.append(i[-1])\n",
    "    \n",
    "X = np.array(X)\n",
    "labels = np.array(labels)\n",
    "\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(X, labels, test_size = 0.1, random_state = 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 9, 100)            269400    \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 300)              301200    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2694)              810894    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,381,494\n",
      "Trainable params: 1,381,494\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(150)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "\n",
    "loss_fn = SparseCategoricalCrossentropy()\n",
    "adam = Adam(learning_rate=0.01)\n",
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8827/8827 [==============================] - 361s 41ms/step - loss: 2.5128 - accuracy: 0.3629 - val_loss: 2.3255 - val_accuracy: 0.3903 - lr: 0.0100\n",
      "Epoch 2/20\n",
      "8827/8827 [==============================] - 348s 39ms/step - loss: 2.2797 - accuracy: 0.3934 - val_loss: 2.3263 - val_accuracy: 0.3988 - lr: 0.0100\n",
      "Epoch 3/20\n",
      "8827/8827 [==============================] - 376s 43ms/step - loss: 2.2874 - accuracy: 0.3918 - val_loss: 2.3550 - val_accuracy: 0.3936 - lr: 0.0100\n",
      "Epoch 4/20\n",
      "8827/8827 [==============================] - 427s 48ms/step - loss: 2.3008 - accuracy: 0.3910 - val_loss: 2.4308 - val_accuracy: 0.3807 - lr: 0.0100\n",
      "Epoch 5/20\n",
      "8827/8827 [==============================] - 501s 57ms/step - loss: 2.1561 - accuracy: 0.4111 - val_loss: 2.2493 - val_accuracy: 0.4116 - lr: 1.0000e-03\n",
      "Epoch 6/20\n",
      "8827/8827 [==============================] - 728s 82ms/step - loss: 2.0628 - accuracy: 0.4246 - val_loss: 2.2147 - val_accuracy: 0.4190 - lr: 1.0000e-03\n",
      "Epoch 7/20\n",
      "8827/8827 [==============================] - 804s 91ms/step - loss: 2.0158 - accuracy: 0.4319 - val_loss: 2.1963 - val_accuracy: 0.4223 - lr: 1.0000e-03\n",
      "Epoch 8/20\n",
      "8827/8827 [==============================] - 857s 97ms/step - loss: 1.9818 - accuracy: 0.4377 - val_loss: 2.1841 - val_accuracy: 0.4254 - lr: 1.0000e-03\n",
      "Epoch 9/20\n",
      "8827/8827 [==============================] - 967s 110ms/step - loss: 1.9588 - accuracy: 0.4403 - val_loss: 2.1751 - val_accuracy: 0.4246 - lr: 1.0000e-03\n",
      "Epoch 10/20\n",
      "8827/8827 [==============================] - 1020s 115ms/step - loss: 1.9335 - accuracy: 0.4450 - val_loss: 2.1699 - val_accuracy: 0.4260 - lr: 1.0000e-03\n",
      "Epoch 11/20\n",
      "8827/8827 [==============================] - 1005s 114ms/step - loss: 1.9169 - accuracy: 0.4486 - val_loss: 2.1662 - val_accuracy: 0.4280 - lr: 1.0000e-03\n",
      "Epoch 12/20\n",
      "8827/8827 [==============================] - 874s 99ms/step - loss: 1.8981 - accuracy: 0.4518 - val_loss: 2.1674 - val_accuracy: 0.4255 - lr: 1.0000e-03\n",
      "Epoch 13/20\n",
      "8827/8827 [==============================] - 724s 82ms/step - loss: 1.8789 - accuracy: 0.4548 - val_loss: 2.1601 - val_accuracy: 0.4296 - lr: 1.0000e-03\n",
      "Epoch 14/20\n",
      "8827/8827 [==============================] - 833s 94ms/step - loss: 1.8660 - accuracy: 0.4566 - val_loss: 2.1543 - val_accuracy: 0.4311 - lr: 1.0000e-03\n",
      "Epoch 15/20\n",
      "8827/8827 [==============================] - 803s 91ms/step - loss: 1.8540 - accuracy: 0.4584 - val_loss: 2.1694 - val_accuracy: 0.4302 - lr: 1.0000e-03\n",
      "Epoch 16/20\n",
      "8827/8827 [==============================] - 738s 83ms/step - loss: 1.8355 - accuracy: 0.4611 - val_loss: 2.1669 - val_accuracy: 0.4324 - lr: 1.0000e-03\n",
      "Epoch 17/20\n",
      "8827/8827 [==============================] - 871s 99ms/step - loss: 1.8221 - accuracy: 0.4637 - val_loss: 2.1733 - val_accuracy: 0.4315 - lr: 1.0000e-03\n",
      "Epoch 18/20\n",
      "8827/8827 [==============================] - 890s 101ms/step - loss: 1.7766 - accuracy: 0.4743 - val_loss: 2.1597 - val_accuracy: 0.4320 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "8827/8827 [==============================] - 842s 95ms/step - loss: 1.7641 - accuracy: 0.4769 - val_loss: 2.1589 - val_accuracy: 0.4322 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "8827/8827 [==============================] - 517s 58ms/step - loss: 1.7577 - accuracy: 0.4788 - val_loss: 2.1579 - val_accuracy: 0.4337 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34c39af520>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 20\n",
    "num_training_samples = len(padded_sentences)\n",
    "num_epochs = 20\n",
    "\n",
    "my_training_batch_generator = My_Generator(x_train, y_train, batch_size)\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(patience=10)\n",
    "                           #, restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(patience=3)\n",
    "\n",
    "model.fit(my_training_batch_generator,\n",
    "                                          steps_per_epoch=(num_training_samples // batch_size),\n",
    "                                          epochs=num_epochs,\n",
    "                                          verbose=1,\n",
    "                                          use_multiprocessing=True,\n",
    "                                          workers=16,\n",
    "                                          max_queue_size=32,\n",
    "                                          validation_data = (x_validate,y_validate),\n",
    "                                          callbacks = [reduce_lr, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('tokenizer_early.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: early/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: early/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f34c3b40700> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f34c3b11250> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"early\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict([[5, 8, 11, 23, 74, 12, 487, 253, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokendict={}\n",
    "for index in range(len(prediction[0])):\n",
    "    tokendict[tokenizer.sequences_to_texts([[index]])[0]] = prediction[0][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df = pd.DataFrame.from_dict({\"moves\": tokendict.keys(), \"probs\": tokendict.values()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moves</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>h6</td>\n",
       "      <td>0.096560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>be7</td>\n",
       "      <td>0.110761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>bb4</td>\n",
       "      <td>0.120348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c5</td>\n",
       "      <td>0.135323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nc6</td>\n",
       "      <td>0.253689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   moves     probs\n",
       "17    h6  0.096560\n",
       "25   be7  0.110761\n",
       "61   bb4  0.120348\n",
       "10    c5  0.135323\n",
       "7    nc6  0.253689"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_df.sort_values(by=\"probs\").tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer.index_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.sequences_to_texts([[5, 8, 11, 23, 74, 12, 487, 253, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.texts_to_sequences([\"d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.texts_to_sequences([\"Bf4+\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[0][56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.sequences_to_texts([[12]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
